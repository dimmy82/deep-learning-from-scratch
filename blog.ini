[:contents]

# はじめに

みなさん、こんにちは！SaaS事業 Product Team の成です。

本日はSWEの経験しかない私が機械学習の開発仕事をやってみて学んだことや感想をシェアしたいと思います。機械学習の観点から見ると入門レベルの内容ですが、よろしくお願いします。

# きっかけ

簡単な自己紹介をさせていただきます。エンジニア経歴は約17年、UBにジョインする前では、SI業界やスマホアプリなどの開発経験を積んできて、8年前UBにジョインしました。UBでも主に自社SaaS事業の各プロダクトの開発をやっています。Product Team（SWE、MLE、SRE、TestEngineerをまとめるエンジニアチームです）ではマイクロフロントエンド・マイクロサービスを推進しており、そのお陰で色な開発言語や技術を触れることができましたが、機械学習の開発経験はまだありませんでした。

Product Teamでは各プロジェクトの開発チームはエンジニア4~5人（職種を跨る場合もある）で、XPというアジャイル手法を徹底的に実施し（日々ペアプロやTDDなどのプラクティスをやっており）、開発を進めております。そして、3ヶ月1回チームシャフルを行い、自分が行ってみたいチームが行けるチャンスがあります。皆さんのWillが優先に考えられますが、場合によっては微調整も行われます。2024の年始から全く機械学習開発の経験がない私がその微調整のお陰で、MLエンジニア3名と4人チームを組んで開発することになりました。

Product Teamを紹介する資料があるので、良かったらご覧ください。
[https://docs.google.com/presentation/d/1S7nUswHaBZOC6YUb4ntj8R37FDRPmQI8UiW5o4y_wR4/edit#slide=id.g8e594dc38e_0_0:embed:cite]

# 何を開発しているか

プロジェクトは2023年の終わり頃始まったので、私は途中参加の形でジョインしました。開発内容は弊社SaaSプロダクトで扱っている企業の概要説明を読み込んで特定なタグを自動付与する仕組みを開発することです。すなわち、企業概要の文章にタグを紐づける分類問題を解決するモデルを開発しています。

最初の2~3ヶ月はまだSWEに近い開発で、主に企業概要を企業APIによって取得したりタグの説明文も別のAPIによって取得し整形したり、パイプラインなどの開発（すなわち、機械学習の前処理の部分）がメインでしたので、以前の開発作業とそんなに大きい差異はなかったですが、3月後半からモデルの訓練、推論や評価など機械学習的な開発段階に入ると知識のギャップを感じてしまい、段々議論のときも発言が少なくなってしまいました。

# 機械学習の門外漢

常にペアプロしているし、チームのMLEの皆さんも優しいので、何か分からないことがあれば随時質問していますが、機械学習知識の土台がない私にとってはピンポイント的な回答は場合によって理解に時間が掛かるし、なかなか定着もできなかったです。もともとはコードを書きながらいつの間に理解できるっしょと思いましたが、ちゃんと機械学習の基礎から学ばないと行けないなと感じてMLEの皆さんに相談したら、「[ゼロから作るDeep Learning](https://www.amazon.co.jp/%E3%82%BC%E3%83%AD%E3%81%8B%E3%82%89%E4%BD%9C%E3%82%8BDeep-Learning-%E2%80%95Python%E3%81%A7%E5%AD%A6%E3%81%B6%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%AE%E7%90%86%E8%AB%96%E3%81%A8%E5%AE%9F%E8%A3%85-%E6%96%8E%E8%97%A4-%E5%BA%B7%E6%AF%85/dp/4873117585/ref=asc_df_4873117585/?tag=jpgo-22&linkCode=df0&hvadid=295686767484&hvpos=&hvnetw=g&hvrand=3091973085756256925&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=1009293&hvtargid=pla-526224399321&psc=1&mcid=352704fd75173223a9e7744302dbfb74&th=1&psc=1)」という本が推奨されました。

4月から2ヶ月をかけて完読しました。「モデルってなに？」、「ロス関数ってなに？」、「なんで正解データで訓練したら精度が高くなるか？」などの疑問は解消できて機械学習のイメージも段々見えてきました。ここで自分の理解を整理してまとめておきます。もし参考になれれば幸いです。

# 機械学習とは

「人工知能」、「機械学習」、「深層学習」、「ニューラルネットワーク」などの単語はよく聞くと思いますが、それぞれどんな関係かも分からなかったのは昔の自分です。ネットで調べたり、本を読んだりして下記の図にまとめてみました。
<figure class="figure-image figure-image-fotolife" title="関係図">[f:id:dimmy82:20240623114113p:plain]<figcaption>関係図</figcaption></figure>

# ニューラルネットワークの推論
「ゼロから作るDeep Learning」は主にニューラルネットワークの訓練や評価についてPythonコード経由で説明してくれました。ニューラルネットワークを一言で言ってみると人間の脳内の神経細胞同士の繋がりを再現した数理モデルだと考えられます。
<figure class="figure-image figure-image-fotolife" title="ニューラルネットワークのイメージ">[f:id:dimmy82:20240623165924p:plain]<figcaption>ニューラルネットワークのイメージ - 出所: https://zero2one.jp/ai-word/neural-network/</figcaption></figure>
右の図はニューラルネットワークの一番シンプルなパターン「パーセプトロン」という構成です。図の中の◯は `ニューロン` といいます。x1, x2は入力値、w1, w2は重みパラメータであり、yは出力値で、その計算式は `y=x1･w1+x2･w2` になります。そしてその計算結果をある関数に挟んで非線形にします。
<figure class="figure-image figure-image-fotolife" title="図: y=2x+10">[f:id:dimmy82:20240624032447p:plain]<figcaption>図: y=2x+10</figcaption></figure>
非線形というのは例えば `y=2x+10` という式があります。図のようにyとxの関係が一直線になります。もし式の結果をそのままyの値にすると、ニューラルネットワークの層が増えると色んな角度の直線が繋がっていく形になるので、それがより良いモデルに訓練しづらいため、ある関数を挟んで非線形にし収束していかないといけないです。その関数は活性化関数といいます。

よく使われる活性化関数は、シグモイド関数であり式は `y=f(x)=1/(1+e^(-x))` になります。図のようにxがどんな値でも、yは必ず(0, 1)の区間になります。xが大きければ大きほどyが1に近づけていくし、xが小さければ小さいほどyが0に近づけていきます。ちなみに、eはネイピア数といい、値は「2.7182818･･･」の無限非循環小数になります。
<figure class="figure-image figure-image-fotolife" title="図: シグモイド関数">[f:id:dimmy82:20240624034123p:plain]<figcaption>図: シグモイド関数</figcaption></figure>
パーセプトロンの計算を詳細まで書くと下記のような図になります。
<figure class="figure-image figure-image-fotolife" title="図: パーセプトロン詳細">[f:id:dimmy82:20240624040156p:plain]<figcaption>図: パーセプトロン詳細</figcaption></figure>
それでは1階層を増やしてより複雑なニューラルネットワークを見てみましょう。まずはここで新しい人物が登場します。バイアスです。図の中に灰色のニューロンの値は常に1であり、それを掛け算しているb･･･はバイアスです。ニューラルネットワークにあるパラメータは主に重みパラメータ（w･･･）とバイアス（b･･･）この2種類です。そして入力値の数や中間層の層数を増えればそのパラメータの数もどんどん増えていきます。ChatGPTなどのLLMのパラメータが数億や数十億と言っている数は主にそのパラメータの数です。
<figure class="figure-image figure-image-fotolife" title="図: より複雑なニューラルネットワーク">[f:id:dimmy82:20240624031941p:plain]<figcaption>図: より複雑なニューラルネットワーク</figcaption></figure>
中間層と出力層の計算式は全部図に書いてありますが、パット見煩雑だなという印象かもしれないですが、それを配列の掛け算として考えてみると分かりやすくなると思います。ちなみにw･･(1)やb･･(1)の括弧にある数字は層を表しています。w･･(1)は1層目を計算するために使っている重みパラメータで、w･･(2)は2層目（出力層）を計算するためのものです。

それでは、中間第1層の計算を例にして説明します。x1, x2, x3は1元配列で考えると `x=[x1, x2, x3]` になります。配列の形を `(行数, 列数)` で表すと `x(1, 3)` になります。重みパラメータwは（w11〜w34）があるので、2元配列で考えてみます。 `w=[[w11, w12, w13, w14], [w21, w22, w23, w24], [w31, w32, w33, w34]]` その形は `w(3, 4)` になります。バイアスは `b=[b1, b2, b3, b4]` になります。1元配列のxと2元配列のwの掛け算は下記の図で考えられます。
<figure class="figure-image figure-image-fotolife" title="図: 配列の掛け算">[f:id:dimmy82:20240624064009p:plain]<figcaption>図: 配列の掛け算</figcaption></figure>
図のようにxの行とwの列を掛け足し算してyの値が決めていきます。仮にxも2元配列でもyの形はこうなります。`x(2, 3)･w(3, 4)=y(2, 4)` になります。掛け算の `左配列の列数` と `右配列の行数` は必ず同じでないといけないので、`w(3, 4)･x(2, 3)` という式は計算できなくなります。

その配列計算のお陰で、ニューラルネットワークの構成は柔軟に調整できます。つまり、中間層にあるニューロンの数はwの列数で決まります。途中で広がっていきたければwの列数を増やせばよいし、最後の出力を2値結果（例のz1とz2）にしたければ、直前のwの列数を2にすればよいです。2値結果は2値分類問題であり、例えばyesかnoかを答えてほしい場合などです。

ちなみに、Pythonがよく機械学習のプログラミングに使われる理由の一つはこういう配列計算は便利なライブラリー（`numpy`ナムパイと言う）があるからです。
<figure class="figure-image figure-image-fotolife" title="図: y = np.dot(x, w)">[f:id:dimmy82:20240624054304p:plain]<figcaption>図: y = np.dot(x, w)</figcaption></figure>
<figure class="figure-image figure-image-fotolife" title="図: y = np.dot(w, x) はエラーになる">[f:id:dimmy82:20240624054353p:plain]<figcaption>図: y = np.dot(w, x) はエラーになる</figcaption></figure>
例外的に片方の配列が1元配列の場合、`w(3, 4)･x(1, 4)=y(1, 3)` という計算はできます。興味があればnumpyで書いてみてください。

上記の方法で層ごとの計算を渡って、z1, z2の値は計算されます。分類問題（例は2値分類問題である）は最終的にパーセンテージで表すことが多いです。z1の確率は `z1/(z1+z2)` になり、z2は `z2/(z1+z2)` になります。つまりz1=0.4でz2=0.1の場合は、z1の確率は80%でz2の確率は20%になります。その処理はSoftmax関数と言います。

最後に入力層は数値の配列なので、例えば「明日は雨が降りますか」のような文字列を何らかの方法で数値の配列にしたり、画像の場合はそのまま縦横のピクセル分の数値2元配列にしたり、このような色んな形式のデータから数値の配列にすることは特徴量の抽出と言います。当然なことですが、入力値はかなりモデルの推論結果に影響するため、特徴量抽出は機械学習エンジニアの腕を見せるところの一つです。

※画像は実際縦横の以外にchannelという軸があり、3元配列ですが、wもchannel文の2元配列を良いすれば計算できます。

上記のように入力値を決め、重みパラメータwと掛け算しバイアスbを足し算して、活性化関数で収束して、その処理を層ごとで繰り返し、最後の結果をSoftmax関数でパーセンテージで表していく。その一連の処理は推論と言います。プログラムではよくforward()という関数で表します。層の階数や最後の結果の数などを自分で決めれば自作のニューラルネットワークが作れます。

# ニューラルネットワークの訓練

モデルの訓練やモデルの学習はよく聞くかもしれないですが、実質は同じことを表しています。それは重みパラメータwとバイアスbを最適に調整することです。wとbは初期値（色々決め方があるので詳細はDLの本をご参照）を決めてからずっと変わらないではなく、何らかの方法でちょっとずつ変更していて正解に近づいていきます。

例えば、例のz1がyesでz2はnoとします。z1が0.4でz2が0.1の場合は、yesの答えは80%でnoは20%になります。ただ、正解はnoのとき、z2は正解と0.4の差があります。（実際はもっと複雑な計算が必要ですが、ここは説明のためにシンプルにまとめました）そのz2の0.4の差を埋めるために、wとbを少しずつ変えていきます。wとbはそれぞれ配列だし、階層が増えればその数が更に増えていきます。具体的にどの値はどう変えるべきかは直感的で判断することは不可能です。そこで微分という数学の知識が必要です。

微分とは、ある瞬間の変化の量を表したものです。例えば、`y=f(x)=2x+10` とうxとyの関数があります。xを極めて小さい数値hの2倍で変更させたら（x+hとx-h）、yはどのぐらい変わるかを計算するのは微分（dy/dx）です。`dy/dx=[df(x+h)-df(x-h)]/2h` という微分式になります。その計算は下記の図にまとめました。
<figure class="figure-image figure-image-fotolife" title="図: 「y=2x+10」の微分">[f:id:dimmy82:20240624072934p:plain]<figcaption>図: 「y=2x+10」の微分</figcaption></figure>
微分（dy/dx）はxの値と関係なく固定値2になります。それは `y=2x+10` が一直線になり、xがどう変更しても、yの変更量が一定になるという解釈になります。

もしyとxの2乗を関係する場合、例えば `y=f(x)=2x^2+10` の微分（dy/dx）は `dy/dx=4x` になり、xとの一直線の関係になります。
<figure class="figure-image figure-image-fotolife" title="図: 「y=2x^2+10」の微分">[f:id:dimmy82:20240624075632p:plain]<figcaption>図: 「y=2x^2+10」の微分</figcaption></figure>
図で理解するとわかりやすいかもしれないですが、`放物線と任意点の接線` という関係になります。
<figure class="figure-image figure-image-fotolife" title="図: 「y=2x^2+10」の微分図">[f:id:dimmy82:20240624080019p:plain]<figcaption>図: 「y=2x^2+10」の微分図</figcaption></figure>